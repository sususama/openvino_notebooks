{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3885b63d",
   "metadata": {},
   "source": [
    "# GSoC pretest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee133ba3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1054aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.quantization as quantization\n",
    "import matplotlib.pyplot as plt\n",
    "from openvino.runtime import Core\n",
    "from openvino.runtime import serialize\n",
    "from openvino.tools import mo\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from onnxruntime.quantization import QuantType, quantize_dynamic\n",
    "from openvino.tools.pot import IEEngine, load_model, save_model, compress_model_weights, create_pipeline\n",
    "from openvino.tools.pot.algorithms.quantization.default.algorithm import DefaultQuantization\n",
    "from openvino.tools.pot.api import DataLoader\n",
    "from openvino.runtime import Core\n",
    "import os\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcc8bcd",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c9d001",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_names = timm.list_models('swin_small*')\n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "model = timm.create_model('swin_small_patch4_window7_224', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809d45df",
   "metadata": {},
   "source": [
    "## Run model at ont-quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3069f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image and preprocess\n",
    "image = Image.open('../notebooks/data/image/coco.jpg')\n",
    "# plt.imshow(image)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.299, 0.224, 0.255])\n",
    "])\n",
    "image = transform(image).unsqueeze(0)\n",
    "\n",
    "# Predict the class of image\n",
    "with torch.no_grad():\n",
    "    output = model(image)\n",
    "    pred = output.argmax(dim=1).item()\n",
    "    print(f'Predicted class: {pred}')\n",
    "# After searching, the 208th category in ImageNet is dog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ca845d",
   "metadata": {},
   "source": [
    "## Define convert model to onnx and IR function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5243d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_models(model, model_input, path):\n",
    "    script_model = torch.jit.trace(model, model_input)\n",
    "    torch.onnx.export(script_model,  model_input, path)   \n",
    "    convert_model = mo.convert_model(path)\n",
    "    # Change the .onnx suffix to .xml\n",
    "    IR_path = path[:-4]+'xml'\n",
    "    serialize(convert_model, IR_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b00144",
   "metadata": {},
   "source": [
    "## Convert model and test them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95ed983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert model to onnx and IR\n",
    "# If you already have a models directory, place comment the next line of code.\n",
    "!mkdir models\n",
    "model.eval()\n",
    "onnx_path = 'models/swin_small_patch4_window7_224.onnx'\n",
    "model_input = torch.randn(1,3,224,224).cpu() \n",
    "convert_models(model, model_input,onnx_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ec329a",
   "metadata": {},
   "source": [
    "## Use built-in quantization to quantize the model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec63c60",
   "metadata": {},
   "source": [
    "### quantize pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8576f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_int8 = quantization.quantize_dynamic(model, dtype=torch.qint8)\n",
    "with torch.no_grad():\n",
    "    output = model_int8(image)\n",
    "    pred = output.argmax(dim=1).item()\n",
    "    print(f'Predicted class: {pred}')\n",
    "torch.save(model_int8, 'models/quantize_swin.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df8ac6",
   "metadata": {},
   "source": [
    "### quantize onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize_path = 'models/quantize_swin.onnx'\n",
    "quantize_dynamic(model_input=onnx_path,\n",
    "    model_output= quantize_path,\n",
    "    weight_type=QuantType.QInt8,\n",
    "    optimize_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae025bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(onnx_model, full_check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f376c77c",
   "metadata": {},
   "source": [
    "### quantize openvino model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b921b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinDataLoader(DataLoader):\n",
    "    def __init__(self, dataset_path):\n",
    "        self._files = []\n",
    "        all_files_in_dir = os.listdir(dataset_path)\n",
    "        for name in  all_files_in_dir:\n",
    "            file = os.path.join(dataset_path, name)\n",
    "            if cv.haveImageReader(file):\n",
    "                self._files.append(file)\n",
    "\n",
    "        self._shape = (1,3, 224,224)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image =  Image.open(self._files[index])\n",
    "        image = transform(image).unsqueeze(0)\n",
    "        return image, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6bd9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_config = [{\n",
    "    'name': 'DefaultQuantization',\n",
    "    'params':{\n",
    "        'target_device': 'ANY',\n",
    "        'stat_subset_size':300,\n",
    "        'stat_batch_size':1,\n",
    "        'model_type': 'transformer'\n",
    "    },\n",
    "}]\n",
    "model_config = {\n",
    "    \"model_name\": \"model\",\n",
    "    \"model\": 'models/swin_small_patch4_window7_224.xml',\n",
    "    \"weights\": 'models/swin_small_patch4_window7_224.bin'\n",
    "}\n",
    "ie = Core()\n",
    "engine_config = {'device': 'CPU'}\n",
    "\n",
    "data_loader = SwinDataLoader('images/')\n",
    "\n",
    "# openvino_model = ie.read_model(model='models/swin_small_patch4_window7_224.xml')\n",
    "openvino_model = load_model(model_config=model_config)\n",
    "\n",
    "engine = IEEngine(config=engine_config, data_loader=data_loader)\n",
    "pipline = create_pipeline(algorithm_config, engine)\n",
    "compressed_model = pipline.run(model=openvino_model)\n",
    "compress_model_weights(compressed_model)\n",
    "compressed_model_paths = save_model(\n",
    "    model=compressed_model,\n",
    "    save_path='models/',\n",
    "    model_name = 'quantization_swin'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9569ae",
   "metadata": {},
   "source": [
    "### quantize to 4 bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e953b229",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_config = [{\n",
    "    'name': 'DefaultQuantization',\n",
    "    'params':{\n",
    "        'target_device': 'ANY',\n",
    "        'stat_subset_size':300,\n",
    "        'stat_batch_size':1,\n",
    "        'model_type': 'transformer',\n",
    "        'bits':4,\n",
    "    },\n",
    "}]\n",
    "openvino_model = load_model(model_config=model_config)\n",
    "pipline = create_pipeline(algorithm_config, engine)\n",
    "compressed_model = pipline.run(model=openvino_model)\n",
    "compress_model_weights(compressed_model)\n",
    "compressed_model_paths = save_model(\n",
    "    model=compressed_model,\n",
    "    save_path='models/',\n",
    "    model_name = 'quantization4_swin'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "384ed1ff3e149b3f0d14d474c781e2b36d523d38367f2a0fc42966152471552f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
