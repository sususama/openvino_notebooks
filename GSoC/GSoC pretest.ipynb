{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3885b63d",
   "metadata": {},
   "source": [
    "# GSoC pretest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee133ba3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1054aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.quantization as quantization\n",
    "import matplotlib.pyplot as plt\n",
    "from openvino.runtime import Core\n",
    "from openvino.runtime import serialize\n",
    "from openvino.tools import mo\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from onnxruntime.quantization import QuantType, quantize_dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcc8bcd",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c9d001",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_names = timm.list_models('swin_small*')\n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "model = timm.create_model('swin_small_patch4_window7_224', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809d45df",
   "metadata": {},
   "source": [
    "## Run model at ont-quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3069f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image and preprocess\n",
    "image = Image.open('../notebooks/data/image/coco.jpg')\n",
    "# plt.imshow(image)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.299, 0.224, 0.255])\n",
    "])\n",
    "image = transform(image).unsqueeze(0)\n",
    "\n",
    "# Predict the class of image\n",
    "with torch.no_grad():\n",
    "    output = model(image)\n",
    "    pred = output.argmax(dim=1).item()\n",
    "    print(f'Predicted class: {pred}')\n",
    "# After searching, the 208th category in ImageNet is dog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ca845d",
   "metadata": {},
   "source": [
    "## Define convert model to onnx and IR function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5243d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_models(model, model_input, path):\n",
    "    script_model = torch.jit.trace(model, model_input)\n",
    "    torch.onnx.export(script_model,  model_input, path)   \n",
    "    convert_model = mo.convert_model(path)\n",
    "    # Change the .onnx suffix to .xml\n",
    "    IR_path = path[:-4]+'xml'\n",
    "    serialize(convert_model, IR_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b00144",
   "metadata": {},
   "source": [
    "## Convert model and test them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95ed983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert model to onnx and IR\n",
    "# If you already have a models directory, place comment the next line of code.\n",
    "!mkdir models\n",
    "model.eval()\n",
    "onnx_path = 'models/swin_small_patch4_window7_224.onnx'\n",
    "model_input = torch.randn(1,3,224,224).cpu() \n",
    "convert_models(model, model_input,onnx_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ec329a",
   "metadata": {},
   "source": [
    "## Use Pytorch built-in quantization to quantize the model and convert them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8576f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ie = Core()\n",
    "# model_ir = ie.read_model(model=(onnx_path[:-4]+'xml'))\n",
    "# model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "model_int8 = quantization.quantize_dynamic(model, dtype=torch.qint8)\n",
    "# quantization.prepare(model, inplace=True)\n",
    "# model_int8 = quantization.convert(model, inplace=True)\n",
    "with torch.no_grad():\n",
    "    output = model_int8(image)\n",
    "    pred = output.argmax(dim=1).item()\n",
    "    print(f'Predicted class: {pred}')\n",
    "torch.save(model_int8, 'models/quantize_swin.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize_path = 'models/quantize_swin.onnx'\n",
    "quantize_dynamic(model_input=onnx_path,\n",
    "    model_output= quantize_path,\n",
    "    weight_type=QuantType.QInt8,\n",
    "    optimize_model=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef69a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_model = mo.convert_model(quantize_path)\n",
    "# Change the .onnx suffix to .xml\n",
    "IR_path = quantize_path[:-4]+'xml'\n",
    "serialize(convert_model, IR_path)\n",
    "# convert_models(torch_model,model_input, quantize_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3a3319",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_int8.eval()\n",
    "quantize_path = 'models/quantize_swin.onnx'\n",
    "# convert_models(model_int8,model_input, quantize_path)\n",
    "# script_model = torch.jit.trace(model_int8, model_input)\n",
    "# torch.onnx.export(script_model,  model_input, quantize_path)\n",
    "# convert_model = mo.convert_model(quantize_path)\n",
    "# # # Change the .onnx suffix to .xml\n",
    "# IR_path = quantize_path[:-4]+'xml'\n",
    "# serialize(convert_model, IR_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "384ed1ff3e149b3f0d14d474c781e2b36d523d38367f2a0fc42966152471552f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
